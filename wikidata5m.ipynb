{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_graph = {}\n",
    "wikidata_name_id = {}\n",
    "wikidata_en_graph = {}\n",
    "wikidata_en_graph = {}\n",
    "wikidata_text = {}\n",
    "wikidata_en_text = {}\n",
    "codex_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = ['P31', 'P279', 'P361'] # instance of, subclass of, part of, these relations are very vague so we discard them\n",
    "with open('wikidata5m_all_triplet.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        if line[1] in find:\n",
    "            continue\n",
    "        if line[0] not in wikidata_graph:\n",
    "            wikidata_graph[line[0]] = {}\n",
    "        if line[1] not in wikidata_graph[line[0]]:\n",
    "            wikidata_graph[line[0]][line[1]] = []\n",
    "        wikidata_graph[line[0]][line[1]].append(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P19': ['Q193722'], 'P106': ['Q39631'], 'P27': ['Q159']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_graph['Q41828']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only choosing relations are unique per entity\n",
    "double_val = []\n",
    "for key, value in wikidata_graph.items():\n",
    "    new_value = {}\n",
    "    for k, v in value.items():\n",
    "        if len(v) > 1:\n",
    "            double_val.append((key, k, v))\n",
    "            continue\n",
    "        new_value[k] = v[0].strip()\n",
    "    wikidata_graph[key] = new_value\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4276852"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidata_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('wikidata5m_text.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        text = line[1].strip()\n",
    "        if len(line) > 2:\n",
    "            for i in range(2, len(line)):\n",
    "                text += ' ' + line[i].strip()\n",
    "        if line[0] in wikidata_graph:\n",
    "            wikidata_text[line[0]] = text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_not_in_text = []\n",
    "possible_entity_names = {}\n",
    "with open('wikidata5m_entity.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        if line[0] not in wikidata_text:\n",
    "            continue\n",
    "        possible_entity_names[line[0]] = line[1:]\n",
    "        possible = line[1:min(30, len(line))] #select most common label from the first 30 aliases\n",
    "        common = ''\n",
    "        all_text = wikidata_text[line[0]]\n",
    "        all_text = unidecode(all_text)\n",
    "        all_text = all_text.lower()\n",
    "        all_text = all_text.replace('–', '-') #replace en dash with hyphen\n",
    "        min_ind = 1000000\n",
    "        #choose common according to the order of the aliases appearing in the text\n",
    "        for name in possible:\n",
    "            name = unidecode(name)\n",
    "            name = name.lower()\n",
    "            if name in all_text:\n",
    "                ind = all_text.index(name)\n",
    "                if ind < min_ind:\n",
    "                    min_ind = ind\n",
    "                    common = name\n",
    "                if min_ind <= 15:\n",
    "                    break\n",
    "        if common == '':\n",
    "            name_not_in_text.append((line[0], all_text, line[1:], possible))\n",
    "            continue\n",
    "        wikidata_name_id[line[0]] = common.strip()\n",
    "with open('wikidata5m_relation.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        wikidata_name_id[line[0]] = unidecode(line[1]).lower()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276852, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidata_graph), len(codex_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3129731"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidata_name_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_en_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_id_name = {}\n",
    "for key, value in wikidata_name_id.items():\n",
    "    wikidata_id_name[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened = 0\n",
    "total = 0\n",
    "for key, value in wikidata_graph.items():\n",
    "    if key not in wikidata_text or key not in wikidata_name_id:\n",
    "        shortened += len(list(value.keys()))\n",
    "        total += len(list(value.keys()))\n",
    "        continue\n",
    "    all_text = wikidata_text[key]\n",
    "    all_text = unidecode(all_text)\n",
    "    all_text = all_text.lower()\n",
    "    all_text = all_text.replace('–', '-')\n",
    "    new_value = {}\n",
    "    for k, v in value.items():\n",
    "        if k in wikidata_name_id and v in wikidata_name_id:\n",
    "            if v in possible_entity_names:\n",
    "                all_possible_vals = possible_entity_names[v]\n",
    "            else:\n",
    "                all_possible_vals = [wikidata_name_id[v]]\n",
    "            for val in all_possible_vals:\n",
    "                val = unidecode(val)\n",
    "                val = val.lower()\n",
    "                ind = all_text.find(val)\n",
    "                if ind != -1:\n",
    "                    new_value[wikidata_name_id[k]] = wikidata_name_id[v]\n",
    "                    if wikidata_name_id[v] not in wikidata_id_name:\n",
    "                        wikidata_id_name[wikidata_name_id[v]] = v\n",
    "                    break\n",
    "            # new_value[wikidata_name_id[k]] = wikidata_name_id[v]\n",
    "            total += 1\n",
    "    if len(new_value) > 0:\n",
    "        wikidata_en_graph[wikidata_name_id[key]] = new_value\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2618411, 3282114, 9912591)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidata_en_graph), shortened, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "keys = []\n",
    "ks = []\n",
    "vs = []\n",
    "for key, value in wikidata_en_graph.items():\n",
    "    if unidecode(key).lower() not in wikidata_id_name:\n",
    "        keys.append(key)\n",
    "    for k, v in value.items():\n",
    "        if unidecode(v).lower() not in wikidata_id_name:\n",
    "            vs.append(v)\n",
    "        if unidecode(k).lower() not in wikidata_id_name:\n",
    "            ks.append(k)\n",
    "len(keys), len(ks), len(vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikidata5m_unidecoded.json', 'w') as f:\n",
    "    json.dump(wikidata_graph, f)\n",
    "with open('wikidata_name_id_uni.json', 'w') as f:\n",
    "    json.dump(wikidata_name_id, f)\n",
    "with open('wikidata_text_uni.json', 'w') as f:\n",
    "    json.dump(wikidata_text, f)\n",
    "with open('wikidata5m_en_unidecoded.json', 'w') as f:\n",
    "    json.dump(wikidata_en_graph, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_id_name = {}\n",
    "for key, value in wikidata_name_id.items():\n",
    "    wikidata_id_name[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_graph_trimmed = {}\n",
    "for key, value in wikidata_graph.items():\n",
    "    if key in wikidata_name_id:\n",
    "        if wikidata_name_id[key] in wikidata_en_graph:\n",
    "            for k, v in value.items():\n",
    "                if k in wikidata_name_id and v in wikidata_name_id:\n",
    "                    if key not in wikidata_graph_trimmed:\n",
    "                        wikidata_graph_trimmed[key] = {}\n",
    "                    wikidata_graph_trimmed[key][k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_en_graph_util = {}\n",
    "for key, value in wikidata_en_graph.items():\n",
    "    wikidata_en_graph_util[key] = {}\n",
    "    for k, v in value.items():\n",
    "        wikidata_en_graph_util[key][v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3123388, 4191605)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata5m_en_text = {}\n",
    "for key, value in wikidata_text.items():\n",
    "    if key in wikidata_name_id:\n",
    "        wikidata5m_en_text[wikidata_name_id[key]] = value\n",
    "len(wikidata5m_en_text), len(wikidata_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikidata5m_en_text.json', 'w') as f:\n",
    "    json.dump(wikidata5m_en_text, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikidata5m_en_util_unidecoded.json', 'w') as f:\n",
    "    json.dump(wikidata_en_graph_util, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 23:54:04.263917: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-31 23:54:04.289948: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-31 23:54:04.420838: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 23:54:04.420871: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 23:54:04.438290: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 23:54:04.482233: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 23:54:05.355589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = json.load(open('wikidata5m_en_graph_util_trimmed.json'))\n",
    "graph_algos = GraphAlgos(wikidata_en_graph_util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('What is the writing system of the official language of the country of dhubab?',\n",
       "  4),\n",
       " 'dhubab',\n",
       " 'arabic alphabet',\n",
       " ['dhubab', 'Yemen', 'Arabic', 'arabic alphabet'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = graph_algos.generate_random_query(k=4, return_path=True)\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
