{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_graph = {}\n",
    "wikidata_name_id = {}\n",
    "wikidata_en_graph = {}\n",
    "wikidata_en_graph = {}\n",
    "wikidata_text = {}\n",
    "wikidata_en_text = {}\n",
    "codex_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = ['P31', 'P279', 'P361'] # instance of, subclass of, part of, these relations are very vague so we discard them\n",
    "with open('/home/vvjain3/rag-llm-verify/wikidata5m_all_triplet.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        if line[1] in find:\n",
    "            continue\n",
    "        if line[0] not in wikidata_graph:\n",
    "            wikidata_graph[line[0]] = {}\n",
    "        if line[1] not in wikidata_graph[line[0]]:\n",
    "            wikidata_graph[line[0]][line[1]] = []\n",
    "        wikidata_graph[line[0]][line[1]].append(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P19': ['Q193722'], 'P106': ['Q39631'], 'P27': ['Q159']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_graph['Q41828']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #only choosing relations are unique per entity\n",
    "# double_val = []\n",
    "# for key, value in wikidata_graph.items():\n",
    "#     new_value = {}\n",
    "#     for k, v in value.items():\n",
    "#         if len(v) > 1:\n",
    "#             double_val.append((key, k, v))\n",
    "#             continue\n",
    "#         new_value[k] = v[0].strip()\n",
    "#     wikidata_graph[key] = new_value\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4276852"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidata_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('wikidata5m_text.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        text = line[1].strip()\n",
    "        if len(line) > 2:\n",
    "            for i in range(2, len(line)):\n",
    "                text += ' ' + line[i].strip()\n",
    "        if line[0] in wikidata_graph:\n",
    "            wikidata_text[line[0]] = text\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1058800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_not_in_text = []\n",
    "possible_entity_names = {}\n",
    "with open('wikidata5m_entity.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        if line[0] not in wikidata_text:\n",
    "            continue\n",
    "        possible_entity_names[line[0]] = line[1:]\n",
    "        possible = line[1:min(30, len(line))] #select most common label from the first 30 aliases\n",
    "        common = ''\n",
    "        all_text = wikidata_text[line[0]]\n",
    "        all_text = unidecode(all_text)\n",
    "        all_text = all_text.lower()\n",
    "        all_text = all_text.replace('–', '-') #replace en dash with hyphen\n",
    "        min_ind = 1000000\n",
    "        #choose common according to the order of the aliases appearing in the text\n",
    "        for name in possible:\n",
    "            name = unidecode(name)\n",
    "            name = name.lower()\n",
    "            if name in all_text:\n",
    "                ind = all_text.index(name)\n",
    "                if ind < min_ind:\n",
    "                    min_ind = ind\n",
    "                    common = name\n",
    "                if min_ind <= 15:\n",
    "                    break\n",
    "        if common == '':\n",
    "            name_not_in_text.append((line[0], all_text, line[1:], possible))\n",
    "            continue\n",
    "        wikidata_name_id[line[0]] = common.strip()\n",
    "with open('wikidata5m_relation.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        line = line.split('\\t')\n",
    "        line = [x.strip() for x in line]\n",
    "        wikidata_name_id[line[0]] = unidecode(line[1]).lower()\n",
    "gc.collect()\n",
    "len(name_not_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3129731"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wikidata_name_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_en_graph = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_id_name = {}\n",
    "for key, value in wikidata_name_id.items():\n",
    "    wikidata_id_name[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4276852, 4276852)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_util = {}\n",
    "for key, value in wikidata_graph.items():\n",
    "    wikidata_util[key] = {}\n",
    "    for rel, objs  in value.items():\n",
    "        for obj in objs:\n",
    "            wikidata_util[key][obj] = rel\n",
    "gc.collect()\n",
    "len(wikidata_util), len(wikidata_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4397801, 21949468)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_wikidata = {}\n",
    "shortened = 0\n",
    "total = 0\n",
    "for key, value in wikidata_util.items():\n",
    "    if key not in wikidata_text or key not in wikidata_name_id:\n",
    "        shortened += len(list(value.keys()))\n",
    "        continue\n",
    "    total += len(list(value.keys()))\n",
    "    all_text = wikidata_text[key]\n",
    "    all_text = unidecode(all_text)\n",
    "    all_text = all_text.lower()\n",
    "    all_text = all_text.replace('–', '-')\n",
    "    new_value = {}\n",
    "    for obj, rel in value.items():\n",
    "        if obj in wikidata_name_id and rel in wikidata_name_id:\n",
    "            if obj in possible_entity_names:\n",
    "                all_possible_vals = possible_entity_names[obj]\n",
    "            else:\n",
    "                all_possible_vals = [wikidata_name_id[obj]]\n",
    "            for val in all_possible_vals:\n",
    "                val = unidecode(val)\n",
    "                val = val.lower()\n",
    "                val = val.strip()\n",
    "                pattern = r'\\b' + re.escape(val) + r'\\b'\n",
    "                matches = re.search(pattern, all_text)\n",
    "                if matches:\n",
    "                    new_value[obj] = rel\n",
    "                    break\n",
    "            total += 1\n",
    "    if len(new_value) > 0:\n",
    "        new_wikidata[key] = new_value\n",
    "gc.collect()\n",
    "shortened, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1147946, 4276852)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shortened = 0\n",
    "total = 0\n",
    "for key, value in wikidata_util.items():\n",
    "    if key not in wikidata_text or key not in wikidata_name_id:\n",
    "        shortened += 1\n",
    "    total += 1\n",
    "shortened, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_graph_util = new_wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in wikidata_graph_util.items():\n",
    "    assert key in wikidata_name_id\n",
    "    assert key in wikidata_text\n",
    "    for k, v in value.items():\n",
    "        assert k in wikidata_name_id\n",
    "        assert v in wikidata_name_id\n",
    "        assert k in wikidata_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1380669, 13714786)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for key, value in wikidata_graph.items():\n",
    "    for rel, objs in value.items():\n",
    "        if len(objs) > 1:\n",
    "            count += 1\n",
    "        total += 1\n",
    "count, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = {}\n",
    "for key, value in wikidata_graph_util.items():\n",
    "    wiki[key] = {}\n",
    "    for k, v in value.items():\n",
    "        if v not in wiki[key]:\n",
    "            wiki[key][v] = []\n",
    "        wiki[key][v].append(k)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206434, 4790905)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for key, value in wiki.items():\n",
    "    for rel, objs in value.items():\n",
    "        if len(objs) > 1:\n",
    "            count += 1\n",
    "        total += 1\n",
    "count, total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wikidata_graphs1/wikidata_name_id.json', 'w') as f:\n",
    "    json.dump(wikidata_name_id, f)\n",
    "with open('wikidata_graphs1/wikidata_text.json', 'w') as f:\n",
    "    json.dump(wikidata_text, f)\n",
    "with open('wikidata_graphs1/wikidata_util.json', 'w') as f:\n",
    "    json.dump(wikidata_graph_util, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vvjain3/.local/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "2024-04-11 07:06:03.984907: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 07:06:04.034584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-11 07:06:04.034616: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-11 07:06:04.036314: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-11 07:06:04.045279: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-11 07:06:05.183859: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/vvjain3/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/vvjain3/.local/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2664259, 3129731, 4191605)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_util = json.load(open('wikidata_graphs1/wikidata_util.json'))\n",
    "wikidata_name_id = json.load(open('wikidata_graphs1/wikidata_name_id.json'))\n",
    "wikidata_text = json.load(open('wikidata_graphs1/wikidata_text.json'))\n",
    "len(wikidata_util), len(wikidata_name_id), len(wikidata_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_aliases = load_aliases('wikidata5m_entity.txt')\n",
    "relation_aliases = load_aliases('wikidata5m_relation.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in wikidata_util.items():\n",
    "    assert key in wikidata_name_id\n",
    "    assert key in wikidata_text\n",
    "    assert key in entity_aliases\n",
    "    for k, v in value.items():\n",
    "        assert k in wikidata_name_id\n",
    "        assert v in wikidata_name_id\n",
    "        assert k in wikidata_text\n",
    "        assert k in entity_aliases\n",
    "        assert v in relation_aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_algos = GraphAlgos(wikidata_util, entity_aliases, relation_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charles lovemore mungoshi humans ['charles lovemore mungoshi', 'writer', 'ritin', 'humans'] What is the played by of the activity corresponding to this occupation of the occupation of Charles Lovemore Mungoshi?\n"
     ]
    }
   ],
   "source": [
    "query_results = graph_algos.generate_random_query(4, return_path=True)\n",
    "path_en = []\n",
    "for i in range(len(query_results[3])):\n",
    "    path_en.append(wikidata_name_id[query_results[3][i]])\n",
    "print(wikidata_name_id[query_results[1]], wikidata_name_id[query_results[3][-1]], path_en, query_results[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1438\n"
     ]
    }
   ],
   "source": [
    "some_vertex =  'Q200482' #'Q453934' #'Q36740'\n",
    "\n",
    "subgraph = graph_algos.create_subgraph_within_radius(some_vertex, 4)\n",
    "print(len(subgraph))\n",
    "subgraph_algos = GraphAlgos(subgraph, entity_aliases, relation_aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 1297, 120, 106)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths = set()\n",
    "all_queries = set()\n",
    "distractors = {}\n",
    "num_correct_answers = []\n",
    "for i in range(4000):\n",
    "    query_results = subgraph_algos.generate_random_query(4, return_path=True, source=some_vertex)\n",
    "    distractor = subgraph_algos.get_best_distractor(query_results[1], query_results[3])\n",
    "    if distractor is None:\n",
    "        continue\n",
    "    # print(f\"Distractor: {distractor}, path: {query_results[3]}\")\n",
    "    num_correct_answers.append(len(query_results[2]))\n",
    "    path_key = tuple(query_results[3])\n",
    "    all_paths.add(path_key)\n",
    "    all_queries.add(query_results[0][0])\n",
    "    if path_key not in distractors:\n",
    "        distractors[path_key] = set()\n",
    "    distractors[path_key].add(distractor) \n",
    "    # if (i+1) % 10 == 0:\n",
    "    #     print(f\"Iteration: {i}, Paths: {len(all_paths)}, Queries: {len(all_queries)}, Distractors: {len(distractors)}\")\n",
    "all_distractors = set()\n",
    "for key, value in distractors.items():\n",
    "    for dis in value:  \n",
    "        all_distractors.add(dis)\n",
    "len(all_paths), len(all_queries), len(distractors), len(all_distractors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
